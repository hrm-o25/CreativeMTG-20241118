<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="./_next/static/css/d1893b45984f5972.css" as="style"/><link rel="stylesheet" href="./_next/static/css/d1893b45984f5972.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="./_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="./_next/static/chunks/webpack-6f0e0dcf15b6875d.js" defer=""></script><script src="./_next/static/chunks/framework-49c6cecf1f6d5795.js" defer=""></script><script src="./_next/static/chunks/main-2564634625bdb2e9.js" defer=""></script><script src="./_next/static/chunks/pages/_app-f73f9933f4da297d.js" defer=""></script><script src="./_next/static/chunks/413-e2aca58274357b3e.js" defer=""></script><script src="./_next/static/chunks/664-fe029c8b38e64ec1.js" defer=""></script><script src="./_next/static/chunks/268-c0dd149334aa5fce.js" defer=""></script><script src="./_next/static/chunks/pages/index-0fc21e2b6fcee3ff.js" defer=""></script><script src="./_next/static/PPoKqxoD2OrYMyxE9sc3b/_buildManifest.js" defer=""></script><script src="./_next/static/PPoKqxoD2OrYMyxE9sc3b/_ssgManifest.js" defer=""></script></head><body><div id="__next"></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"result":{"clusters":[{"cluster":"参加者の応援と関心","cluster_id":"1","takeaways":"ComoNeチームへのコメントは、参加者の熱意と楽しさが伝わる内容でした。アイデアが出ない瞬間や、実際にノーションを見たいという声があり、アクティビティの設計が高く評価されています。また、ユーモアや親しみやすさを感じさせるコメントも多く、チームの雰囲気が明るいことが伺えます。全体として、参加者はComoNeの活動に期待を寄せている様子が見受けられました。","arguments":[{"arg_id":"A0_0","argument":"ありがとうございます","comment_id":"0","x":18.76088,"y":8.180735,"p":0.899694463097765},{"arg_id":"A1_0","argument":"おにぎりめちゃうまでした！！！🍙","comment_id":"1","x":19.796206,"y":7.5769587,"p":1},{"arg_id":"A3_0","argument":"ComoNeチームがんばれー！","comment_id":"3","x":19.494106,"y":7.3146963,"p":1},{"arg_id":"A8_0","argument":"ComoNeへのコメント！スタートです！","comment_id":"8","x":19.349426,"y":7.336615,"p":0},{"arg_id":"A14_0","argument":"アイデア出ない時ある！","comment_id":"14","x":19.38811,"y":6.9566135,"p":1},{"arg_id":"A19_0","argument":"土だったんだ！！","comment_id":"19","x":20.004156,"y":7.928089,"p":1},{"arg_id":"A22_0","argument":"土！！！","comment_id":"22","x":20.233818,"y":8.193938,"p":1},{"arg_id":"A24_0","argument":"WAZAありぃ！！","comment_id":"24","x":19.987165,"y":7.5993447,"p":1},{"arg_id":"A25_0","argument":"つち！！","comment_id":"25","x":19.987135,"y":7.9117594,"p":1},{"arg_id":"A26_0","argument":"ちゃんと土をいじる！！","comment_id":"26","x":20.141796,"y":7.9250546,"p":1},{"arg_id":"A33_0","argument":"のじまくん2回目の登壇！レギュラー入り","comment_id":"33","x":19.620762,"y":7.0855494,"p":0.4325418824920879},{"arg_id":"A43_0","argument":"マジでデカいです、屋根登ってます。みなさんもいずれは登れます！","comment_id":"43","x":19.642017,"y":7.127408,"p":0.7913633484956761},{"arg_id":"A49_0","argument":"おおおお〜！","comment_id":"49","x":19.56422,"y":8.415575,"p":0.9429449097554328},{"arg_id":"A51_0","argument":"ノーション実際にみてみたい！","comment_id":"51","x":19.217993,"y":6.936099,"p":0.48402471303426},{"arg_id":"A52_0","argument":"おもしろかった！","comment_id":"52","x":19.394423,"y":7.0551896,"p":1},{"arg_id":"A54_0","argument":"おつかれピース✌️","comment_id":"54","x":19.272268,"y":8.185332,"p":1},{"arg_id":"A68_0","argument":"みんな来夏来てね","comment_id":"68","x":19.009811,"y":7.57356,"p":1},{"arg_id":"A72_0","argument":"サイン250個、、！","comment_id":"72","x":20.263447,"y":8.129467,"p":1},{"arg_id":"A85_0","argument":"AKXYコメントスタート！","comment_id":"85","x":18.836409,"y":7.2779827,"p":0.535674409186002},{"arg_id":"A90_0","argument":"AI？","comment_id":"90","x":19.558949,"y":8.835042,"p":0.7437448864259395},{"arg_id":"A91_0","argument":"ヘイ、尻！","comment_id":"91","x":19.721252,"y":8.53014,"p":1},{"arg_id":"A101_0","argument":"この次は家族になろうよ","comment_id":"101","x":18.843233,"y":7.618279,"p":1},{"arg_id":"A102_0","argument":"うまいアクティビティの設計だ！！","comment_id":"102","x":19.419683,"y":6.9672127,"p":1},{"arg_id":"A113_0","argument":"今晩行こうよ","comment_id":"113","x":18.90695,"y":7.59214,"p":1},{"arg_id":"A118_0","argument":"イヒ","comment_id":"118","x":19.392511,"y":8.892162,"p":1},{"arg_id":"A119_0","argument":"イヒ","comment_id":"119","x":19.412903,"y":8.951388,"p":1},{"arg_id":"A121_0","argument":"罪の共有！すごいパンチライン","comment_id":"121","x":19.453362,"y":7.685541,"p":0},{"arg_id":"A132_0","argument":"合宿で詰めるのわかる！ComoNeも展示でやった！","comment_id":"132","x":19.744226,"y":6.87526,"p":1},{"arg_id":"A143_0","argument":"みわちゃんだ！！","comment_id":"143","x":20.01611,"y":7.739081,"p":1},{"arg_id":"A144_0","argument":"京都盛り上がってる！","comment_id":"144","x":19.916603,"y":7.262411,"p":0},{"arg_id":"A154_0","argument":"大好評の展示！","comment_id":"154","x":19.882317,"y":6.7852325,"p":1},{"arg_id":"A163_0","argument":"niziU","comment_id":"163","x":19.478836,"y":8.990529,"p":1},{"arg_id":"A164_0","argument":"胆力！！","comment_id":"164","x":20.287327,"y":8.175952,"p":1},{"arg_id":"A174_0","argument":"ワザきた！","comment_id":"174","x":20.003597,"y":7.4266143,"p":1},{"arg_id":"A180_0","argument":"だだん！","comment_id":"180","x":19.86273,"y":8.171094,"p":0},{"arg_id":"A185_0","argument":"ダンダダン","comment_id":"185","x":19.810886,"y":8.398412,"p":1},{"arg_id":"A218_0","argument":"すごい！！","comment_id":"218","x":19.64149,"y":7.365224,"p":1},{"arg_id":"A221_0","argument":"すごい！！","comment_id":"221","x":19.656239,"y":7.4511485,"p":1},{"arg_id":"A222_0","argument":"ヨコクでもやってましたね！！","comment_id":"222","x":19.933397,"y":7.536539,"p":1},{"arg_id":"A228_0","argument":"胃袋！","comment_id":"228","x":20.344017,"y":8.314617,"p":0.4341699684798131},{"arg_id":"A248_0","argument":"なかよし！！","comment_id":"248","x":19.828318,"y":7.73127,"p":1},{"arg_id":"A253_0","argument":"あのマークサットンに！！","comment_id":"253","x":20.147429,"y":7.7712097,"p":1},{"arg_id":"A257_0","argument":"学会展示すごいー！","comment_id":"257","x":19.73749,"y":6.792036,"p":1},{"arg_id":"A263_0","argument":"私もググった","comment_id":"263","x":19.230501,"y":7.974665,"p":1},{"arg_id":"A266_0","argument":"チ","comment_id":"266","x":19.559689,"y":9.10222,"p":0.6218277793488739},{"arg_id":"A269_0","argument":"豚汁京都","comment_id":"269","x":18.993315,"y":8.44472,"p":0},{"arg_id":"A272_0","argument":"え！今日から？","comment_id":"272","x":19.407082,"y":8.105624,"p":1}]},{"cluster":"参加者の感情的な反応","cluster_id":"7","takeaways":"参加者のコメントは、アイドルグループやメンバーに対する親しみや愛情を表現しており、特に「りょうくん」や「みわちゃん」に対する反応が目立つ。彼らの外見や表情、さらにはパフォーマンスに対する感想が多く、ファン同士の絆や共感も感じられる。また、「丁寧」や「明るい人」といった言葉からは、メンバーの人柄や魅力についての深い理解が伺える。全体として、楽しさや感動が溢れる雰囲気が伝わってくる。","arguments":[{"arg_id":"A2_0","argument":"おっけ","comment_id":"2","x":19.037004,"y":9.516402,"p":0.7570910644702237},{"arg_id":"A5_0","argument":"なんかアイドルグループみたいだ","comment_id":"5","x":17.567848,"y":9.064468,"p":0.5178298803086756},{"arg_id":"A6_0","argument":"仲良さそうだな","comment_id":"6","x":17.760128,"y":8.924737,"p":1},{"arg_id":"A15_0","argument":"たなはしがんばれ","comment_id":"15","x":18.490932,"y":9.135057,"p":1},{"arg_id":"A16_0","argument":"はじめw","comment_id":"16","x":17.73972,"y":10.124287,"p":0},{"arg_id":"A17_0","argument":"こわいですねw","comment_id":"17","x":17.971369,"y":9.758113,"p":1},{"arg_id":"A20_0","argument":"つくりたいな〜　こわい","comment_id":"20","x":17.76772,"y":9.539798,"p":1},{"arg_id":"A29_0","argument":"偶発的","comment_id":"29","x":17.621784,"y":9.446082,"p":0.8507542327373556},{"arg_id":"A35_0","argument":"顔","comment_id":"35","x":18.820087,"y":9.555884,"p":0.9705165567028776},{"arg_id":"A76_0","argument":"あ、そういうことか。","comment_id":"76","x":17.989403,"y":9.23705,"p":1},{"arg_id":"A87_0","argument":"りょうくんは生きてるの？","comment_id":"87","x":17.845827,"y":9.860533,"p":1},{"arg_id":"A92_0","argument":"死にそうな神様","comment_id":"92","x":17.930853,"y":9.697722,"p":0.8821015055811201},{"arg_id":"A93_0","argument":"愛人","comment_id":"93","x":18.43495,"y":9.981644,"p":1},{"arg_id":"A94_0","argument":"仲間=愛人","comment_id":"94","x":18.222197,"y":9.960308,"p":0.5949602629619125},{"arg_id":"A95_0","argument":"おじちゃんの表情ええなあ〜","comment_id":"95","x":18.096436,"y":8.878054,"p":1},{"arg_id":"A106_0","argument":"どれだけ本気になってもらえるのか","comment_id":"106","x":17.083675,"y":9.121769,"p":1},{"arg_id":"A107_0","argument":"りょうくん、老けたなw","comment_id":"107","x":17.918753,"y":9.948959,"p":0},{"arg_id":"A137_0","argument":"めちゃうれしそうw","comment_id":"137","x":17.91098,"y":9.281472,"p":0.8492051599048138},{"arg_id":"A142_0","argument":"病み上がりで振り絞ってる感","comment_id":"142","x":17.812586,"y":9.551088,"p":0.7253867990042621},{"arg_id":"A145_0","argument":"てづくりの汁","comment_id":"145","x":18.911238,"y":8.818845,"p":0},{"arg_id":"A146_0","argument":"汁","comment_id":"146","x":19.266495,"y":9.200599,"p":0.4381536651520212},{"arg_id":"A148_0","argument":"しる","comment_id":"148","x":18.643091,"y":9.099446,"p":1},{"arg_id":"A149_0","argument":"かわいいい","comment_id":"149","x":18.25839,"y":8.963726,"p":1},{"arg_id":"A169_0","argument":"だんだん恐くなってきた","comment_id":"169","x":17.687338,"y":9.463359,"p":1},{"arg_id":"A171_0","argument":"ごかぁぁん","comment_id":"171","x":18.78911,"y":9.381215,"p":0.9962204448024404},{"arg_id":"A172_2","argument":"互換","comment_id":"172","x":17.289314,"y":9.414998,"p":0},{"arg_id":"A173_0","argument":"え、めちゃエモいやん","comment_id":"173","x":18.228416,"y":9.507935,"p":0},{"arg_id":"A175_0","argument":"わざきたぁ","comment_id":"175","x":18.648205,"y":9.132495,"p":0.9934973576433368},{"arg_id":"A177_0","argument":"それそれ〜","comment_id":"177","x":19.045511,"y":8.9582205,"p":0.3990113877906914},{"arg_id":"A179_0","argument":"ジャンプしりたい","comment_id":"179","x":17.50431,"y":9.502647,"p":0.592552055859359},{"arg_id":"A182_0","argument":"でた、デサイロ","comment_id":"182","x":18.672476,"y":9.644163,"p":0.9705165567028776},{"arg_id":"A189_0","argument":"みわちゃんパワーやな","comment_id":"189","x":17.820553,"y":8.6268015,"p":1},{"arg_id":"A193_0","argument":"ちかくにいるけどみえない...","comment_id":"193","x":18.622484,"y":9.391188,"p":1},{"arg_id":"A194_0","argument":"みわちゃんの背景も怖く感じてきた","comment_id":"194","x":17.762133,"y":9.043845,"p":0.8492880964550248},{"arg_id":"A198_0","argument":"かっけえ","comment_id":"198","x":18.685133,"y":9.512609,"p":1},{"arg_id":"A206_0","argument":"最高やな","comment_id":"206","x":18.294441,"y":8.504014,"p":1},{"arg_id":"A211_0","argument":"愛","comment_id":"211","x":18.504107,"y":9.999028,"p":1},{"arg_id":"A214_0","argument":"愛だ","comment_id":"214","x":18.407545,"y":9.916206,"p":1},{"arg_id":"A220_0","argument":"わざあり言うてくれてる笑","comment_id":"220","x":18.294094,"y":8.880516,"p":1},{"arg_id":"A225_0","argument":"愛あるなー","comment_id":"225","x":18.109676,"y":9.382718,"p":1},{"arg_id":"A227_0","argument":"ああ、丁寧ってそういうことか（言われることが自分も多いけど、どれが丁寧だといわれているか自覚がなかった）","comment_id":"227","x":17.681522,"y":8.957102,"p":1},{"arg_id":"A230_0","argument":"明るい人、なるほど","comment_id":"230","x":17.776173,"y":8.921367,"p":1},{"arg_id":"A236_0","argument":"一卵性双生児気になる","comment_id":"236","x":17.35468,"y":9.166858,"p":0.3942692260831795},{"arg_id":"A237_0","argument":"お疲れ","comment_id":"237","x":18.991158,"y":9.588489,"p":0.9585111328053886},{"arg_id":"A238_0","argument":"なんか含みがあるなー","comment_id":"238","x":18.315735,"y":9.216668,"p":0},{"arg_id":"A244_0","argument":"良い言葉","comment_id":"244","x":17.481728,"y":8.793599,"p":0},{"arg_id":"A247_0","argument":"えー、みわちゃん元気そうで嬉しいわ","comment_id":"247","x":18.035084,"y":9.09686,"p":0.8492051599048138},{"arg_id":"A262_0","argument":"コペ転","comment_id":"262","x":17.038465,"y":9.244477,"p":0.9203674088767708},{"arg_id":"A271_0","argument":"あれして笑","comment_id":"271","x":18.484686,"y":9.041131,"p":0.92578104581105}]},{"cluster":"参加者の具体的な反応","cluster_id":"6","takeaways":"参加者は、プロジェクトにおけるクリエイティブなアプローチやデザインの重要性について多様な意見を述べました。特に、アクティビティを通じての共同作業が楽しさや実感を生むこと、クリエイターの選出基準やその背景に興味を持つ声が多く見られました。また、言葉やメモからの発想の連鎖や、グラフィックデザインの力についても高く評価されており、クリエイターとの対話が貴重であるとの意見が強調されました。","arguments":[{"arg_id":"A4_0","argument":"n大文字なんだ","comment_id":"4","x":17.72468,"y":7.075456,"p":1},{"arg_id":"A10_0","argument":"小上がりすてき","comment_id":"10","x":17.852894,"y":8.375914,"p":0.7786265691112509},{"arg_id":"A11_0","argument":"難しい大きさの表し方","comment_id":"11","x":17.76236,"y":6.7844644,"p":0.6704150637405392},{"arg_id":"A12_0","argument":"櫃石のしゃべり技あり","comment_id":"12","x":17.157583,"y":7.564933,"p":0.913869290625695},{"arg_id":"A27_0","argument":"勇気ある知識人、です","comment_id":"27","x":17.14612,"y":8.623863,"p":1},{"arg_id":"A28_0","argument":"なんかすごい図がいっぱいある","comment_id":"28","x":17.631008,"y":7.019309,"p":1},{"arg_id":"A36_0","argument":"単語がいちいちかっこいい","comment_id":"36","x":17.596636,"y":8.478608,"p":1},{"arg_id":"A38_0","argument":"同じ景色を見る","comment_id":"38","x":17.16616,"y":6.5983396,"p":0},{"arg_id":"A44_0","argument":"一緒にいじったり、アクティビティをプロセスにちゃんと入れるのいいよね、楽しくなるもんね。つくってる実感得られるもんね。","comment_id":"44","x":17.435217,"y":7.69573,"p":1},{"arg_id":"A47_0","argument":"googleダメ多いもんね・・","comment_id":"47","x":17.783981,"y":7.1429844,"p":1},{"arg_id":"A48_0","argument":"のーしょん教えてください","comment_id":"48","x":18.587063,"y":8.125276,"p":0.9544204388595684},{"arg_id":"A55_0","argument":"これわざよりやった人がすごい","comment_id":"55","x":17.37574,"y":8.074439,"p":1},{"arg_id":"A58_0","argument":"勇気ある知識人","comment_id":"58","x":16.743906,"y":8.801705,"p":1},{"arg_id":"A60_0","argument":"アートとかサインはやってないの？","comment_id":"60","x":16.406588,"y":7.448011,"p":0.8427311703909186},{"arg_id":"A65_0","argument":"ゲストかどうかとかで変わってそうな気がする・・・","comment_id":"65","x":15.839256,"y":6.604534,"p":0},{"arg_id":"A66_0","argument":"あまりにもpjが大きすぎると各分野を横串するものが必要なきがするのですがどういったものがありますか？","comment_id":"66","x":17.562216,"y":6.5378995,"p":0.6194316727745154},{"arg_id":"A69_0","argument":"サインデザインもやっています。デザインは終わり、今見積もりと施工者決めていくフェイズです〜","comment_id":"69","x":15.859405,"y":7.2777586,"p":1},{"arg_id":"A70_0","argument":"なぜ竹本さんなのか気になった","comment_id":"70","x":16.34929,"y":6.834509,"p":1},{"arg_id":"A73_0","argument":"アート作れるのいいな","comment_id":"73","x":16.947182,"y":7.454753,"p":0.913869290625695},{"arg_id":"A74_0","argument":"竹本さんはもううちが入る前から決まってたのですよ。建築家がアサインしたらしい","comment_id":"74","x":16.159878,"y":6.987461,"p":1},{"arg_id":"A77_0","argument":"芝生でお酒最高ですね","comment_id":"77","x":18.445951,"y":7.702493,"p":0},{"arg_id":"A79_0","argument":"クリエイター選べないの難しくないかな","comment_id":"79","x":16.344288,"y":7.5556884,"p":1},{"arg_id":"A82_0","argument":"そもそもなんの視察か気になる","comment_id":"82","x":15.959012,"y":6.822032,"p":0.9527197156080534},{"arg_id":"A84_0","argument":"ここもこもねなんすね https://www.thers.ac.jp/about/org/common_nexus/common_nexus.html","comment_id":"84","x":18.140854,"y":7.4006395,"p":0.9692635340990956},{"arg_id":"A88_0","argument":"けいくんの髪型も旭化成？","comment_id":"88","x":16.515854,"y":6.798559,"p":0.9650661482892332},{"arg_id":"A99_0","argument":"どの写真も説明ないと勘違いする楽しそう","comment_id":"99","x":18.091953,"y":7.973629,"p":1},{"arg_id":"A100_0","argument":"富士吉田もさいこう","comment_id":"100","x":17.784245,"y":7.512122,"p":0},{"arg_id":"A103_0","argument":"プロンプトうたないと","comment_id":"103","x":16.793259,"y":8.09196,"p":0},{"arg_id":"A110_0","argument":"押谷さんとも仲間になるのが大事ってことだ","comment_id":"110","x":17.64592,"y":7.9137464,"p":0.8704397161817629},{"arg_id":"A112_0","argument":"コメントおもろい","comment_id":"112","x":18.056955,"y":7.727507,"p":1},{"arg_id":"A120_0","argument":"罪の共有だな","comment_id":"120","x":18.45915,"y":8.417669,"p":1},{"arg_id":"A128_0","argument":"もう仕事じゃないってすごい","comment_id":"128","x":16.974113,"y":7.8632073,"p":0},{"arg_id":"A134_0","argument":"AKXY LabのWebページや取材の更新もLWがやってるんですか？","comment_id":"134","x":18.298306,"y":7.198176,"p":0.9692635340990956},{"arg_id":"A136_0","argument":"今後の運用体制が気になる","comment_id":"136","x":15.691396,"y":7.3944497,"p":0},{"arg_id":"A141_0","argument":"口車すごい","comment_id":"141","x":18.039072,"y":8.239581,"p":0.8059080373739312},{"arg_id":"A151_0","argument":"プロジェクト名は固い","comment_id":"151","x":16.436522,"y":7.9611473,"p":0.8837712517995907},{"arg_id":"A153_0","argument":"Fabcafe kyotoという場所があるのか","comment_id":"153","x":16.697712,"y":6.5635586,"p":0},{"arg_id":"A155_0","argument":"FabCafeに感じない","comment_id":"155","x":16.554852,"y":6.5446467,"p":0.9650661482892332},{"arg_id":"A156_0","argument":"クリエイターさんのアサインはどういった軸で選出したのですか？","comment_id":"156","x":16.231882,"y":7.4221444,"p":0.800073401963907},{"arg_id":"A161_0","argument":"すごい","comment_id":"161","x":18.084682,"y":8.318296,"p":0.9294399112517654},{"arg_id":"A167_0","argument":"決める技必要ですな","comment_id":"167","x":16.572752,"y":7.7953324,"p":0.6375919316621178},{"arg_id":"A178_0","argument":"村上さんのたくさんのわざも気になる！","comment_id":"178","x":16.925428,"y":6.951439,"p":1},{"arg_id":"A181_0","argument":"稲川淳二師匠呼んでほしかった","comment_id":"181","x":16.857311,"y":7.0562396,"p":1},{"arg_id":"A188_0","argument":"誰か来週これ行かない？ https://www.juryoku.com/","comment_id":"188","x":18.584812,"y":7.3366065,"p":0},{"arg_id":"A195_0","argument":"なにげない言葉のメモから発想につながっている","comment_id":"195","x":17.259779,"y":8.646481,"p":0.6429043572757421},{"arg_id":"A199_0","argument":"みわちゃんのひらめき力すごい","comment_id":"199","x":17.581478,"y":8.336688,"p":0},{"arg_id":"A200_0","argument":"環境づくり大事","comment_id":"200","x":16.65335,"y":8.338649,"p":0},{"arg_id":"A203_0","argument":"ただのタスク管理じゃないPMの安定感","comment_id":"203","x":16.44629,"y":8.03841,"p":1},{"arg_id":"A204_0","argument":"すご","comment_id":"204","x":18.607294,"y":8.319073,"p":0.9544204388595684},{"arg_id":"A205_0","argument":"なにをデザインしたのか気になる","comment_id":"205","x":16.01443,"y":7.1882267,"p":1},{"arg_id":"A207_0","argument":"企画ほやほやでアサインするの怖さあるからすごい","comment_id":"207","x":16.736462,"y":7.72756,"p":1},{"arg_id":"A208_0","argument":"企画ほやほやで口説けるのすごい","comment_id":"208","x":16.908434,"y":7.8115315,"p":1},{"arg_id":"A209_0","argument":"グラフィックってそういう力あるよね","comment_id":"209","x":17.38732,"y":7.1885085,"p":0.5528796114432019},{"arg_id":"A210_0","argument":"絵にするって大事よね","comment_id":"210","x":16.891191,"y":7.453149,"p":0},{"arg_id":"A216_0","argument":"デザイナーさんの顔が、、、、ゾゾゾ","comment_id":"216","x":16.141216,"y":7.4414506,"p":0.744531780361523},{"arg_id":"A217_0","argument":"時間内に打ち合わせ終わる大事","comment_id":"217","x":16.586136,"y":8.166523,"p":1},{"arg_id":"A219_0","argument":"村上くん、仕事一緒にしたいす","comment_id":"219","x":17.02873,"y":7.170287,"p":1},{"arg_id":"A223_0","argument":"プラスアルファのコメント大事","comment_id":"223","x":18.041162,"y":7.510339,"p":1},{"arg_id":"A226_0","argument":"クリエイターさんからの声きけるの貴重すぎる","comment_id":"226","x":16.385134,"y":7.580336,"p":0.8427311703909186},{"arg_id":"A231_0","argument":"デザイナーさんの名前知りたい","comment_id":"231","x":16.173687,"y":7.6276984,"p":0.610072300339706},{"arg_id":"A233_0","argument":"クリエイターさんからこんなにワザ評価してもらえるのすごい","comment_id":"233","x":16.48637,"y":7.705503,"p":0.7017550466475071},{"arg_id":"A234_0","argument":"一緒にやった人からこんな反応もらえることが、すばらしいわざの証明だなぁ","comment_id":"234","x":17.397732,"y":7.937838,"p":1},{"arg_id":"A235_0","argument":"最高やな","comment_id":"235","x":18.26736,"y":8.399927,"p":0.9655287446086246},{"arg_id":"A245_0","argument":"明日忘れる説明になってないですかそれは？　自問自答だな","comment_id":"245","x":18.243368,"y":8.050292,"p":0},{"arg_id":"A246_0","argument":"無関心を受け入れる","comment_id":"246","x":16.947483,"y":8.994378,"p":1},{"arg_id":"A249_0","argument":"タコパの関係性","comment_id":"249","x":17.0581,"y":8.365192,"p":1},{"arg_id":"A250_0","argument":"タコ切ってくれてる","comment_id":"250","x":17.281113,"y":8.2259865,"p":1},{"arg_id":"A251_0","argument":"ステークホルダーとめちゃくちゃ仲良くなっててすごい","comment_id":"251","x":17.726088,"y":7.7955785,"p":0},{"arg_id":"A252_0","argument":"事前にタコ用意は愛深い","comment_id":"252","x":17.065857,"y":8.480934,"p":1},{"arg_id":"A255_0","argument":"いや文献あたったことがあるってそれすごいな","comment_id":"255","x":17.296438,"y":7.745876,"p":1},{"arg_id":"A256_0","argument":"アカデミアに認められてるのすごい","comment_id":"256","x":17.528643,"y":7.6145444,"p":0},{"arg_id":"A259_0","argument":"クリエイターアサインの基準","comment_id":"259","x":16.231577,"y":7.5633445,"p":1},{"arg_id":"A267_0","argument":"感性を働かせてインプットする","comment_id":"267","x":16.704218,"y":8.965773,"p":1},{"arg_id":"A268_0","argument":"発想を根本的に変えることによって、ものごとの新しい局面を切り開くことのたとえ。らしい","comment_id":"268","x":16.842537,"y":8.671869,"p":0}]},{"cluster":"参加者の具体的な反応","cluster_id":"0","takeaways":"参加者は、棚橋くんのTシャツやロゴに関するコメントを多く寄せ、特にそのデザインや面白さに注目している。また、プロジェクトの一環としての展示物やループ図についても関心が高く、どのようにコンテンツが構築されたのか、またその効果についての疑問が見受けられる。ビデオレターに対する反応も好意的で、参加者たちはその内容を楽しんでいる様子が伺える。全体として、プロジェクトのクリエイティブな要素に対する興味と期待が強く表れたコメントが多かった。","arguments":[{"arg_id":"A7_0","argument":"しっかりTシャツ着てる棚橋くん。","comment_id":"7","x":17.206957,"y":5.6177616,"p":1},{"arg_id":"A9_0","argument":"ロゴ複雑だね","comment_id":"9","x":18.518251,"y":6.0631056,"p":1},{"arg_id":"A13_0","argument":"棚橋くんのプロフ写真良い","comment_id":"13","x":16.98152,"y":5.900248,"p":0.6782032495316268},{"arg_id":"A18_0","argument":"この世で見たことがないロゴ","comment_id":"18","x":18.1299,"y":5.7893434,"p":1},{"arg_id":"A21_0","argument":"棚橋くんのTシャツなんて書いてあるんだろう","comment_id":"21","x":17.129848,"y":5.6754637,"p":0.9472464750709289},{"arg_id":"A23_0","argument":"雨の中棚橋くんと土拾いに行ったね笑","comment_id":"23","x":17.06396,"y":5.798161,"p":0.6782032495316268},{"arg_id":"A30_0","argument":"ロゴの作り方が面白い！","comment_id":"30","x":18.782587,"y":6.113559,"p":1},{"arg_id":"A31_0","argument":"どんどんロゴ変わっ","comment_id":"31","x":18.47526,"y":5.979423,"p":0},{"arg_id":"A32_0","argument":"ロゴ面白い！","comment_id":"32","x":18.92122,"y":6.1556616,"p":0},{"arg_id":"A42_0","argument":"既製品家具で1億規模のPJです！","comment_id":"42","x":17.560799,"y":6.3146076,"p":0},{"arg_id":"A50_0","argument":"棚橋くんのTシャツはどこで買えるのか","comment_id":"50","x":17.104818,"y":5.6700034,"p":0.7951937378235341},{"arg_id":"A56_0","argument":"棚橋Tシャツは名大で買えます！","comment_id":"56","x":17.272173,"y":5.577021,"p":1},{"arg_id":"A57_0","argument":"Tシャツいいですね","comment_id":"57","x":17.293386,"y":5.5885663,"p":1},{"arg_id":"A61_0","argument":"ノーションの使い方すごい勉強になる〜","comment_id":"61","x":18.489214,"y":7.040992,"p":0.4572055333212128},{"arg_id":"A67_0","argument":"かっこいいロゴですね","comment_id":"67","x":18.159771,"y":5.8409534,"p":1},{"arg_id":"A71_0","argument":"展示物面白そう！どんな狙いや効果を見込んでコンテンツを作る流れになったのか、気になる。","comment_id":"71","x":19.038027,"y":6.5243945,"p":0},{"arg_id":"A150_0","argument":"窒素問題","comment_id":"150","x":18.80743,"y":6.4491587,"p":0.5547173461289553},{"arg_id":"A159_0","argument":"ループ図ぅ！","comment_id":"159","x":18.514194,"y":6.510945,"p":1},{"arg_id":"A160_0","argument":"ループ図","comment_id":"160","x":18.40939,"y":6.4265637,"p":1},{"arg_id":"A162_0","argument":"ループ図20個やばい","comment_id":"162","x":18.389822,"y":6.4373045,"p":0.9773131951451532},{"arg_id":"A165_0","argument":"このループ図フェーズからどうやってジャンプしたのか、窒素と怪談","comment_id":"165","x":18.669483,"y":6.480122,"p":0.849884248765729},{"arg_id":"A168_0","argument":"ループ図すごい。どこに注力するかの選定が難しそう","comment_id":"168","x":18.252165,"y":6.435059,"p":0.8545483700488593},{"arg_id":"A170_0","argument":"棚橋さんの天の声希望","comment_id":"170","x":16.894556,"y":5.9689274,"p":0.3792639758223218},{"arg_id":"A196_0","argument":"キャロルって名前お化けっぽくていいですね","comment_id":"196","x":18.111198,"y":5.8663783,"p":1},{"arg_id":"A201_0","argument":"カリイボーイのイラストだ","comment_id":"201","x":17.989332,"y":5.9175153,"p":0.4242685690777658},{"arg_id":"A212_0","argument":"ビデオレター愛あるすごいー！","comment_id":"212","x":19.653093,"y":6.245936,"p":1},{"arg_id":"A213_0","argument":"ビデオレターきたの笑","comment_id":"213","x":19.752998,"y":6.134893,"p":0.8560309345097298},{"arg_id":"A215_0","argument":"ビデオレター💌","comment_id":"215","x":19.688454,"y":6.1906056,"p":1},{"arg_id":"A224_0","argument":"この動画、永久保存してみんな毎週見たらいいと思う","comment_id":"224","x":19.620687,"y":6.2177176,"p":1},{"arg_id":"A232_0","argument":"ビデオレター嬉しい","comment_id":"232","x":19.7437,"y":6.1118674,"p":0.7588214985352988},{"arg_id":"A241_0","argument":"ループさせよう","comment_id":"241","x":18.5514,"y":6.7533445,"p":0.5486585225902533},{"arg_id":"A258_0","argument":"階段登ってるね","comment_id":"258","x":19.0149,"y":6.8978963,"p":0},{"arg_id":"A261_0","argument":"コペルニクス的展開","comment_id":"261","x":18.532303,"y":6.62739,"p":1}]},{"cluster":"参加者の反応の特徴","cluster_id":"3","takeaways":"参加者は「天の声」や「天と地のコラボレーション」というテーマを通じて、古天文学に関する興味深い視点を共有しました。特に、地域による言葉の違いや、空中戦と地上戦の関係性についてのユーモアを交えた議論が展開され、天動説と地動説の対比も話題に上がりました。全体として、古天文学の概念を現代の視点で再解釈する試みが見られました。","arguments":[{"arg_id":"A34_0","argument":"古天文学しりたい","comment_id":"34","x":16.796535,"y":10.874146,"p":1},{"arg_id":"A86_0","argument":"天の声","comment_id":"86","x":16.57421,"y":10.5340805,"p":0.910926484550583},{"arg_id":"A89_0","argument":"天の声すごい","comment_id":"89","x":16.564104,"y":10.397063,"p":1},{"arg_id":"A104_0","argument":"天の声ですw","comment_id":"104","x":16.68733,"y":10.418932,"p":0.79877325646385},{"arg_id":"A105_0","argument":"天の声はちょっと遅れてやってくる","comment_id":"105","x":16.540617,"y":10.473921,"p":1},{"arg_id":"A129_0","argument":"天と地のコラボレーション","comment_id":"129","x":16.739166,"y":10.8176985,"p":1},{"arg_id":"A130_0","argument":"天と地w","comment_id":"130","x":16.86863,"y":10.703565,"p":1},{"arg_id":"A131_0","argument":"天と地のコラボレーション？","comment_id":"131","x":16.746681,"y":10.893364,"p":1},{"arg_id":"A147_0","argument":"「とんじる」っていうか「ぶたじる」っていうか、地域差ありますよね","comment_id":"147","x":17.203876,"y":10.180015,"p":0},{"arg_id":"A239_0","argument":"空中戦w","comment_id":"239","x":17.003662,"y":10.742969,"p":0.9065926337271868},{"arg_id":"A240_0","argument":"天と地のコラボレーションってこと？","comment_id":"240","x":16.77222,"y":10.789683,"p":1},{"arg_id":"A242_0","argument":"天と地でたw","comment_id":"242","x":16.927984,"y":10.760701,"p":1},{"arg_id":"A243_0","argument":"「空中戦を地上戦に」企画書でマネしたいひとこと","comment_id":"243","x":16.875616,"y":10.736592,"p":1},{"arg_id":"A264_0","argument":"つまり全ては天と地のコラボレーションってことだ","comment_id":"264","x":16.70706,"y":10.892985,"p":1},{"arg_id":"A265_0","argument":"天動説じゃなくて地動説だった！的なやつでしたっけ","comment_id":"265","x":16.907343,"y":10.899193,"p":0.8300832735820232}]},{"cluster":"参加者の具体的な反応","cluster_id":"5","takeaways":"参加者は、Notionを活用した原価管理やプロジェクトの整理方法について関心を示し、特にテンプレートの共有やクライアントとの連携に関する質問が多く見られました。また、予算に関する具体的な金額や経費の取り扱いについての話題もあり、特に旭化成との関係や運用予算の確保についての疑問が浮かび上がりました。さらに、キュレーションや提案資料に関する情報交換も行われ、参加者同士の知識共有が活発に行われていました。","arguments":[{"arg_id":"A37_0","argument":"金額感すごい","comment_id":"37","x":15.472045,"y":9.142455,"p":1},{"arg_id":"A39_0","argument":"500000000円の原価管理してます","comment_id":"39","x":15.160548,"y":9.080646,"p":1},{"arg_id":"A40_0","argument":"5億","comment_id":"40","x":15.725987,"y":9.284897,"p":1},{"arg_id":"A41_0","argument":"5億！？","comment_id":"41","x":15.923133,"y":9.359057,"p":1},{"arg_id":"A45_0","argument":"notionならOKとかあるのか！！！！","comment_id":"45","x":14.352405,"y":7.335053,"p":0.3808856258283575},{"arg_id":"A46_0","argument":"TAAPでつかいたいなやっぱりnotion","comment_id":"46","x":14.526878,"y":7.3928623,"p":0.4681923852083601},{"arg_id":"A53_0","argument":"Notionテンプレートほしい","comment_id":"53","x":14.426701,"y":7.484396,"p":1},{"arg_id":"A59_0","argument":"Notionをクライアントに共有するときって、課金とかは必要ないんですか？","comment_id":"59","x":14.449666,"y":7.6539,"p":0.3714223909668462},{"arg_id":"A62_0","argument":"notion見たいです！整理方法とかが参考になりそう！","comment_id":"62","x":14.396551,"y":7.4284725,"p":0.7263944177241892},{"arg_id":"A63_0","argument":"notionの料金設定知りたい","comment_id":"63","x":14.3724375,"y":7.512546,"p":1},{"arg_id":"A64_0","argument":"notionてもうかってんのかな","comment_id":"64","x":14.3475485,"y":7.5028987,"p":0.7815969445195058},{"arg_id":"A75_0","argument":"営業が空間を語るとしたら？","comment_id":"75","x":14.805702,"y":8.488961,"p":1},{"arg_id":"A78_0","argument":"ちなみにサインとオブジェで合計2000万くらいの予算です〜","comment_id":"78","x":15.328594,"y":8.840947,"p":1},{"arg_id":"A80_0","argument":"2000万かージリ貧だー","comment_id":"80","x":15.195397,"y":9.148329,"p":1},{"arg_id":"A81_0","argument":"入場は無料ですか？","comment_id":"81","x":14.806357,"y":8.639993,"p":1},{"arg_id":"A83_0","argument":"無料です","comment_id":"83","x":16.056929,"y":8.759379,"p":0},{"arg_id":"A108_0","argument":"謎の領収書w","comment_id":"108","x":14.737805,"y":9.671495,"p":0},{"arg_id":"A111_0","argument":"経費落とせるんだ笑","comment_id":"111","x":14.76194,"y":9.236816,"p":1},{"arg_id":"A113_1","argument":"経費","comment_id":"113","x":14.714514,"y":9.27605,"p":1},{"arg_id":"A116_0","argument":"メンバーにりょうくんをいらたら経費でいいらしい","comment_id":"116","x":14.548098,"y":9.351155,"p":1},{"arg_id":"A124_0","argument":"もう旭化成からお金が出ていないってことですか？","comment_id":"124","x":14.903257,"y":8.562039,"p":1},{"arg_id":"A125_0","argument":"お金はどうしてるの？","comment_id":"125","x":14.886418,"y":8.816088,"p":1},{"arg_id":"A127_0","argument":"クライアントがいなくなって成長するってすごいな。チャレンジング！","comment_id":"127","x":15.204693,"y":8.207814,"p":0.9275779724898736},{"arg_id":"A135_0","argument":"毎年の予算どうやって取ってるんやろ？","comment_id":"135","x":15.074003,"y":8.820379,"p":1},{"arg_id":"A138_0","argument":"クライアントがいなくなったってことは、もう運用予算はないということですか…？","comment_id":"138","x":14.915379,"y":8.30418,"p":1},{"arg_id":"A139_0","argument":"収束費用","comment_id":"139","x":14.805874,"y":9.085428,"p":1},{"arg_id":"A140_0","argument":"収束費用って何ですか？","comment_id":"140","x":14.686937,"y":8.883286,"p":1},{"arg_id":"A152_0","argument":"キュレーションに関するわざ知りたい","comment_id":"152","x":15.764359,"y":8.086084,"p":0},{"arg_id":"A157_0","argument":"AWRDはどう絡んでるんだ？","comment_id":"157","x":15.227985,"y":8.711269,"p":1},{"arg_id":"A158_0","argument":"予算知りたいです","comment_id":"158","x":15.35962,"y":8.480814,"p":1},{"arg_id":"A172_0","argument":"五感","comment_id":"172","x":16.452482,"y":9.186439,"p":0},{"arg_id":"A172_1","argument":"5巻","comment_id":"172","x":16.104464,"y":9.295185,"p":0.7985556753542112},{"arg_id":"A202_0","argument":"提案資料もきになる","comment_id":"202","x":15.694888,"y":8.2643385,"p":0},{"arg_id":"A229_0","argument":"クライアントの胃袋をつかむ","comment_id":"229","x":15.500856,"y":8.603629,"p":0.9928947717960692}]},{"cluster":"ガールズバーに関する議論","cluster_id":"4","takeaways":"参加者はガールズバーに関する話題で盛り上がり、経費として落とす方法やその合法性についての興味を示しています。特に、クライアントとの関係構築やビジネスの一環としての利用が強調されており、ガールズバーを訪れることが仕事にどのように関連するかについての議論が行われています。また、軽いジョークやカジュアルな表現が多く、楽しさやリラックスした雰囲気も感じられます。","arguments":[{"arg_id":"A96_0","argument":"ガールズバーに行ったことを良く言ってるww","comment_id":"96","x":13.763981,"y":9.686825,"p":1},{"arg_id":"A97_0","argument":"ガールズバーはどうやって経費で落とせるんですか？教えてください。","comment_id":"97","x":14.013224,"y":9.478778,"p":0.9174154488595176},{"arg_id":"A98_0","argument":"ガールズバーいまから行こうよ","comment_id":"98","x":13.704109,"y":9.695413,"p":0.739254195834788},{"arg_id":"A109_0","argument":"ガールズバーは経費でおとせることが判明","comment_id":"109","x":14.103853,"y":9.592976,"p":1},{"arg_id":"A114_0","argument":"ガールズバーを経費で落とすワザ知りたい","comment_id":"114","x":13.996542,"y":9.721547,"p":0.8705442766453307},{"arg_id":"A115_0","argument":"ガールズバーのこと経費呼んでるw","comment_id":"115","x":14.008316,"y":9.652718,"p":1},{"arg_id":"A117_0","argument":"クライアントの女の子を追いかける","comment_id":"117","x":14.095181,"y":9.3426285,"p":0},{"arg_id":"A122_0","argument":"まさか、いまガールズバーか？","comment_id":"122","x":13.738374,"y":9.608956,"p":0.6521835658085008},{"arg_id":"A123_0","argument":"ガールズバーいっちゃったから","comment_id":"123","x":13.573004,"y":9.8285,"p":0.2393424154500763},{"arg_id":"A126_0","argument":"ガールズバーで稼いでる","comment_id":"126","x":13.787562,"y":9.65454,"p":1},{"arg_id":"A133_0","argument":"ガールズバーどこまでオーケーなのか","comment_id":"133","x":13.748742,"y":9.676727,"p":1},{"arg_id":"A260_0","argument":"ヴァイブス経営","comment_id":"260","x":14.500098,"y":9.413866,"p":1},{"arg_id":"A270_0","argument":"女子会？","comment_id":"270","x":13.571478,"y":9.831837,"p":0.2349999125740215}]},{"cluster":"怪談に対する関心と反応","cluster_id":"2","takeaways":"参加者は、怪談の魅力や実話怪談の存在について興味を示し、怪談師の発想や技術に感心している様子が伺えます。実話怪談が実際に起こった出来事を基にしていることや、様々な人からの話を集めて語るスタイルに対する関心も高まっています。また、怪談の流行や、特に悪い関係性に関する話に対する期待感も表れています。","arguments":[{"arg_id":"A166_0","argument":"まだ怪談感ない","comment_id":"166","x":15.3378525,"y":6.0121813,"p":1},{"arg_id":"A176_0","argument":"怪談師","comment_id":"176","x":15.461712,"y":6.0681353,"p":1},{"arg_id":"A183_0","argument":"実話怪談とかあるのかこわい","comment_id":"183","x":15.278443,"y":5.959806,"p":1},{"arg_id":"A184_0","argument":"実話怪談にどうたどり着いたの…","comment_id":"184","x":15.5292635,"y":6.1883698,"p":0.5731106952751374},{"arg_id":"A186_0","argument":"怪談師の発想すごい","comment_id":"186","x":15.409172,"y":6.111717,"p":1},{"arg_id":"A187_0","argument":"怪談って流行ってるん！？","comment_id":"187","x":15.304109,"y":5.995391,"p":1},{"arg_id":"A190_0","argument":"実話怪談って実際に起った怪談・・・？","comment_id":"190","x":15.415997,"y":6.1284313,"p":1},{"arg_id":"A191_0","argument":"いろんな人から怪談聞き集めて語る怪談師がいて、聞いた話をそのまま話すらしい","comment_id":"191","x":15.428949,"y":6.0920596,"p":1},{"arg_id":"A192_0","argument":"急に横見て話しはじめた感じ怪談ぽい","comment_id":"192","x":15.399932,"y":6.061102,"p":1},{"arg_id":"A197_0","argument":"もはやみわちゃんの怪談ナレッジがすごい","comment_id":"197","x":15.219165,"y":5.896957,"p":0.9148598079693588},{"arg_id":"A254_0","argument":"悪い関係性の話も今度聞きたくなるな","comment_id":"254","x":15.213864,"y":5.922025,"p":1}]}],"comments":{"0":{"comment":"ありがとうございます"},"1":{"comment":"おにぎりめちゃうまでした！！！🍙"},"2":{"comment":"おっけ"},"3":{"comment":"ComoNeチームがんばれー！"},"4":{"comment":"n大文字なんだ"},"5":{"comment":"なんかアイドルグループみたいだ"},"6":{"comment":"仲良さそうだな"},"7":{"comment":"しっかりTシャツ着てる棚橋くん。"},"8":{"comment":"ComoNeへのコメント！スタートです！"},"9":{"comment":"ロゴ複雑だね"},"10":{"comment":"小上がりすてき"},"11":{"comment":"難しい大きさの表し方"},"12":{"comment":"櫃石のしゃべり技あり"},"13":{"comment":"棚橋くんのプロフ写真良い"},"14":{"comment":"アイデア出ない時ある！"},"15":{"comment":"たなはしがんばれ"},"16":{"comment":"はじめw"},"17":{"comment":"こわいですねw"},"18":{"comment":"この世で見たことがないロゴ"},"19":{"comment":"土だったんだ！！"},"20":{"comment":"つくりたいな〜　こわい"},"21":{"comment":"棚橋くんのTシャツなんて書いてあるんだろう"},"22":{"comment":"土！！！"},"23":{"comment":"雨の中棚橋くんと土拾いに行ったね笑"},"24":{"comment":"WAZAありぃ！！"},"25":{"comment":"つち！！"},"26":{"comment":"ちゃんと土をいじる！！"},"27":{"comment":"勇気ある知識人、です"},"28":{"comment":"なんかすごい図がいっぱいある"},"29":{"comment":"偶発的"},"30":{"comment":"ロゴの作り方が面白い！"},"31":{"comment":"どんどんロゴ変わっ"},"32":{"comment":"ロゴ面白い！"},"33":{"comment":"のじまくん2回目の登壇！レギュラー入り"},"34":{"comment":"古天文学しりたい"},"35":{"comment":"顔"},"36":{"comment":"単語がいちいちかっこいい"},"37":{"comment":"金額感すごい"},"38":{"comment":"同じ景色を見る"},"39":{"comment":"500000000円の原価管理してます"},"40":{"comment":"5億"},"41":{"comment":"5億！？"},"42":{"comment":"既製品家具で1億規模のPJです！"},"43":{"comment":"マジでデカいです、屋根登ってます。みなさんもいずれは登れます！"},"44":{"comment":"一緒にいじったり、アクティビティをプロセスにちゃんと入れるのいいよね、楽しくなるもんね。つくってる実感得られるもんね。"},"45":{"comment":"notionならOKとかあるのか！！！！"},"46":{"comment":"TAAPでつかいたいなやっぱりnotion"},"47":{"comment":"googleダメ多いもんね・・"},"48":{"comment":"のーしょん教えてください"},"49":{"comment":"おおおお〜！"},"50":{"comment":"棚橋くんのTシャツはどこで買えるのか"},"51":{"comment":"ノーション実際にみてみたい！"},"52":{"comment":"おもしろかった！"},"53":{"comment":"Notionテンプレートほしい"},"54":{"comment":"おつかれピース✌️"},"55":{"comment":"これわざよりやった人がすごい"},"56":{"comment":"棚橋Tシャツは名大で買えます！"},"57":{"comment":"Tシャツいいですね"},"58":{"comment":"勇気ある知識人"},"59":{"comment":"Notionをクライアントに共有するときって、課金とかは必要ないんですか？"},"60":{"comment":"アートとかサインはやってないの？"},"61":{"comment":"ノーションの使い方すごい勉強になる〜"},"62":{"comment":"notion見たいです！整理方法とかが参考になりそう！"},"63":{"comment":"notionの料金設定知りたい"},"64":{"comment":"notionてもうかってんのかな"},"65":{"comment":"ゲストかどうかとかで変わってそうな気がする・・・"},"66":{"comment":"あまりにもpjが大きすぎると各分野を横串するものが必要なきがするのですがどういったものがありますか？"},"67":{"comment":"かっこいいロゴですね"},"68":{"comment":"みんな来夏来てね"},"69":{"comment":"サインデザインもやっています。デザインは終わり、今見積もりと施工者決めていくフェイズです〜"},"70":{"comment":"なぜ竹本さんなのか気になった"},"71":{"comment":"展示物面白そう！どんな狙いや効果を見込んでコンテンツつくる流れになったのか、気になる"},"72":{"comment":"サイン250個、、！"},"73":{"comment":"アート作れるのいいな"},"74":{"comment":"竹本さんはもううちが入る前から決まってたのですよ。建築家がアサインしたらしい"},"75":{"comment":"営業が空間を語るとしたら？"},"76":{"comment":"あ、そういうことか。"},"77":{"comment":"芝生でお酒最高ですね"},"78":{"comment":"ちなみにサインとオブジェで合計2000万くらいの予算です〜"},"79":{"comment":"クリエイター選べないの難しくないかな"},"80":{"comment":"2000万かージリ貧だー"},"81":{"comment":"入場は無料ですか？"},"82":{"comment":"そもそもなんの視察か気になる"},"83":{"comment":"無料です"},"84":{"comment":"ここもこもねなんすね https://www.thers.ac.jp/about/org/common_nexus/common_nexus.html"},"85":{"comment":"AKXYコメントスタート！"},"86":{"comment":"天の声"},"87":{"comment":"りょうくんは生きてるの？"},"88":{"comment":"けいくんの髪型も旭化成？"},"89":{"comment":"天の声すごい"},"90":{"comment":"AI？"},"91":{"comment":"ヘイ、尻！"},"92":{"comment":"死にそうな神様"},"93":{"comment":"愛人"},"94":{"comment":"仲間=愛人"},"95":{"comment":"おじちゃんの表情ええなあ〜"},"96":{"comment":"ガールズバーに行ったことを良く言ってるww"},"97":{"comment":"ガールズバーはどうやって経費で落とせるんですか？教えてください"},"98":{"comment":"ガールズバーいまから行こうよ"},"99":{"comment":"どの写真も説明ないと勘違いする楽しそう"},"100":{"comment":"富士吉田もさいこう"},"101":{"comment":"この次は家族になろうよ"},"102":{"comment":"うまいアクティビティの設計だ！！"},"103":{"comment":"プロンプトうたないと"},"104":{"comment":"天の声ですw"},"105":{"comment":"天の声はちょっと遅れてやってくる"},"106":{"comment":"どれだけ本気になってもらえるのか"},"107":{"comment":"りょうくん、老けたなw"},"108":{"comment":"謎の領収書w"},"109":{"comment":"ガールズバーは経費でおとせることが判明"},"110":{"comment":"押谷さんとも仲間になるのが大事ってことだ"},"111":{"comment":"経費落とせるんだ笑"},"112":{"comment":"コメントおもろい"},"113":{"comment":"今晩行こうよ　経費"},"114":{"comment":"ガールズバーを経費で落とすワザ知りたい"},"115":{"comment":"ガールズバーのこと経費呼んでるw"},"116":{"comment":"メンバーにりょうくんをいらたら経費でいいらしい"},"117":{"comment":"クライアントの女の子を追いかける"},"118":{"comment":"イヒ"},"119":{"comment":"イヒ"},"120":{"comment":"罪の共有だな"},"121":{"comment":"罪の共有！すごいパンチライン"},"122":{"comment":"まさか、いまガールズバーか？"},"123":{"comment":"ガールズバーいっちゃったから"},"124":{"comment":"もう旭化成からお金が出ていないってことですか？"},"125":{"comment":"お金はどうしてるの？"},"126":{"comment":"ガールズバーで稼いでる"},"127":{"comment":"クライアントがいなくなって成長するってすごいな。チャレンジング！"},"128":{"comment":"もう仕事じゃないってすごい"},"129":{"comment":"天と地のコラボレーション"},"130":{"comment":"天と地w"},"131":{"comment":"天と地のコラボレーション？"},"132":{"comment":"合宿で詰めるのわかる！ComoNeも展示でやった！"},"133":{"comment":"ガールズバーどこまでオーケーなのか"},"134":{"comment":"AKXY LabのWebページや取材の更新もLWがやってるんですか？"},"135":{"comment":"毎年の予算どうやって取ってるんやろ？"},"136":{"comment":"今後の運用体制が気になる"},"137":{"comment":"めちゃうれしそうw"},"138":{"comment":"クライアントがいなくなったってことは、もう運用予算はないということですか…？"},"139":{"comment":"収束費用"},"140":{"comment":"収束費用って何ですか？"},"141":{"comment":"口車すごい"},"142":{"comment":"病み上がりで振り絞ってる感"},"143":{"comment":"みわちゃんだ！！"},"144":{"comment":"京都盛り上がってる！"},"145":{"comment":"てづくりの汁"},"146":{"comment":"汁"},"147":{"comment":"「とんじる」っていうか「ぶたじる」っていうか、地域差ありますよね"},"148":{"comment":"しる"},"149":{"comment":"かわいいい"},"150":{"comment":"窒素問題"},"151":{"comment":"プロジェクト名は固い"},"152":{"comment":"キュレーションに関するわざ知りたい"},"153":{"comment":"Fabcafe kyotoという場所があるのか"},"154":{"comment":"大好評の展示！"},"155":{"comment":"FabCafeに感じない"},"156":{"comment":"クリエイターさんのアサインはどういった軸で選出したのですか？"},"157":{"comment":"AWRDはどう絡んでるんだ？"},"158":{"comment":"予算知りたいです"},"159":{"comment":"ループ図ぅ！"},"160":{"comment":"ループ図"},"161":{"comment":"すごい"},"162":{"comment":"ループ図20個やばい"},"163":{"comment":"niziU"},"164":{"comment":"胆力！！"},"165":{"comment":"このループ図フェーズからどうやってジャンプしたのか、窒素と怪談"},"166":{"comment":"まだ怪談感ない"},"167":{"comment":"決める技必要ですな"},"168":{"comment":"ループ図すごい。どこに注力するかの選定が難しそう"},"169":{"comment":"だんだん恐くなってきた"},"170":{"comment":"棚橋さんの天の声希望"},"171":{"comment":"ごかぁぁん"},"172":{"comment":"五感、5巻、互換"},"173":{"comment":"え、めちゃエモいやん"},"174":{"comment":"ワザきた！"},"175":{"comment":"わざきたぁ"},"176":{"comment":"怪談師"},"177":{"comment":"それそれ〜"},"178":{"comment":"村上さんのたくさんのわざも気になる！"},"179":{"comment":"ジャンプしりたい"},"180":{"comment":"だだん！"},"181":{"comment":"稲川淳二師匠呼んでほしかった"},"182":{"comment":"でた、デサイロ"},"183":{"comment":"実話怪談とかあるのかこわい"},"184":{"comment":"実話怪談にどうたどり着いたの…"},"185":{"comment":"ダンダダン"},"186":{"comment":"怪談師の発想すごい"},"187":{"comment":"怪談って流行ってるん！？"},"188":{"comment":"誰か来週これ行かない？ https://www.juryoku.com/"},"189":{"comment":"みわちゃんパワーやな"},"190":{"comment":"実話怪談って実際に起った怪談・・・？"},"191":{"comment":"いろんな人から怪談聞き集めて語る怪談師がいて、聞いた話をそのまま話すらしい"},"192":{"comment":"急に横見て話しはじめた感じ怪談ぽい"},"193":{"comment":"ちかくにいるけどみえない..."},"194":{"comment":"みわちゃんの背景も怖く感じてきた"},"195":{"comment":"なにげない言葉のメモから発想につながっている"},"196":{"comment":"キャロルって名前お化けっぽくていいですね"},"197":{"comment":"もはやみわちゃんの怪談ナレッジがすごい"},"198":{"comment":"かっけえ"},"199":{"comment":"みわちゃんのひらめき力すごい"},"200":{"comment":"環境づくり大事"},"201":{"comment":"カリイボーイのイラストだ"},"202":{"comment":"提案資料もきになる"},"203":{"comment":"ただのタスク管理じゃないPMの安定感"},"204":{"comment":"すご"},"205":{"comment":"なにをデザインしたのか気になる"},"206":{"comment":"最高やな"},"207":{"comment":"企画ほやほやでアサインするの怖さあるからすごい"},"208":{"comment":"企画ほやほやで口説けるのすごい"},"209":{"comment":"グラフィックってそういう力あるよね"},"210":{"comment":"絵にするって大事よね"},"211":{"comment":"愛"},"212":{"comment":"ビデオレター愛あるすごいー！"},"213":{"comment":"ビデオレターきたの笑"},"214":{"comment":"愛だ"},"215":{"comment":"ビデオレター💌"},"216":{"comment":"デザイナーさんの顔が、、、、ゾゾゾ"},"217":{"comment":"時間内に打ち合わせ終わる大事"},"218":{"comment":"すごい！！"},"219":{"comment":"村上くん、仕事一緒にしたいす"},"220":{"comment":"わざあり言うてくれてる笑"},"221":{"comment":"すごい！！"},"222":{"comment":"ヨコクでもやってましたね！！"},"223":{"comment":"プラスアルファのコメント大事"},"224":{"comment":"この動画、永久保存してみんな毎週見たらいいと思う"},"225":{"comment":"愛あるなー"},"226":{"comment":"クリエイターさんからの声きけるの貴重すぎる"},"227":{"comment":"ああ、丁寧ってそういうことか（言われることが自分も多いけど、どれが丁寧だといわれているか自覚がなかった）"},"228":{"comment":"胃袋！"},"229":{"comment":"クライアントの胃袋をつかむ"},"230":{"comment":"明るい人、なるほど"},"231":{"comment":"デザイナーさんの名前知りたい"},"232":{"comment":"ビデオレター嬉しい"},"233":{"comment":"クリエイターさんからこんなにワザ評価してもらえるのすごい"},"234":{"comment":"一緒にやった人からこんな反応もらえることが、すばらしいわざの証明だなぁ"},"235":{"comment":"最高やな"},"236":{"comment":"一卵性双生児気になる"},"237":{"comment":"お疲れ"},"238":{"comment":"なんか含みがあるなー"},"239":{"comment":"空中戦w"},"240":{"comment":"天と地のコラボレーションってこと？"},"241":{"comment":"ループさせよう"},"242":{"comment":"天と地でたw"},"243":{"comment":"「空中戦を地上戦に」企画書でマネしたいひとこと"},"244":{"comment":"良い言葉"},"245":{"comment":"明日忘れる説明になってないですかそれは？　自問自答だな"},"246":{"comment":"無関心を受け入れる"},"247":{"comment":"えー、みわちゃん元気そうで嬉しいわ"},"248":{"comment":"なかよし！！"},"249":{"comment":"タコパの関係性"},"250":{"comment":"タコ切ってくれてる"},"251":{"comment":"ステークホルダーとめちゃくちゃ仲良くなっててすごい"},"252":{"comment":"事前にタコ用意は愛深い"},"253":{"comment":"あのマークサットンに！！"},"254":{"comment":"悪い関係性の話も今度聞きたくなるな"},"255":{"comment":"いや文献あたったことがあるってそれすごいな"},"256":{"comment":"アカデミアに認められてるのすごい"},"257":{"comment":"学会展示すごいー！"},"258":{"comment":"階段登ってるね"},"259":{"comment":"クリエイターアサインの基準"},"260":{"comment":"ヴァイブス経営"},"261":{"comment":"コペルニクス的展開"},"262":{"comment":"コペ転"},"263":{"comment":"私もググった"},"264":{"comment":"つまり全ては天と地のコラボレーションってことだ"},"265":{"comment":"天動説じゃなくて地動説だった！的なやつでしたっけ"},"266":{"comment":"チ"},"267":{"comment":"感性を働かせてインプットする"},"268":{"comment":"発想を根本的に変えることによって、ものごとの新しい局面を切り開くことのたとえ。らしい"},"269":{"comment":"豚汁京都"},"270":{"comment":"女子会？"},"271":{"comment":"あれして笑"},"272":{"comment":"え！今日から？"}},"overview":"参加者の反応は多岐にわたり、各クラスターからはプロジェクトへの熱意や関心が強く感じられます。ComoNeチームへの応援や、アイドルメンバーへの愛情が特に目立ち、クリエイティブなアプローチやデザインに対する具体的な意見も多く寄せられました。また、古天文学やガールズバーに関するユーモアを交えた議論、さらには怪談への興味も見受けられ、参加者同士の知識共有やリラックスした雰囲気が醸成されています。全体として、参加者はプロジェクトに対する期待感と楽しさを強く表現しています。","config":{"name":"Creative MTG 反応まとめ","question":"Creative MTGの参加者の反応にはどういう傾向があったのか","input":"CreativeMTG","model":"gpt-4o-mini","extraction":{"workers":3,"limit":273,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nあなたはプロのリサーチアシスタントであり、私の仕事は論拠のきれいなデータセットを準備することです。\n\n背景として、私はCreative MTGに参加した人のコメントを集めています。\nCreative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nCreative MTGでどのような反応があったのかを分類するお手伝いをしていただきたいです。\nこれから与えるのはCreative MTGに参加した人のコメントのリストです。\nこれから与える投稿をJSONリストとして返してほしい。\n本当に必要な場合は、2つ以上の別々の意見に分けることもできるが、1つのトピックを返すのが最善であることが多いだろう。\n以下にポストを要約する際の事例を挙げます。\nこれらはあくまで文脈の切り離された例であり、この例で与えた文章を返すことはしないでください。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\n\n\n/human\n\n気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\n\n/ai \n\n[\n  \"気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\"\n]\n\n/human \n\n豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\n\n/ai \n\n[\n  \"豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\",\n]\n\n/human\n\nAI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\n\n/ai\n\n[\n  \"AI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\"\n]\n\n\n/human\n\nいい\n\n/ai\n\n[\n  \"いい\"\n]\n\n/human\n\nあとで読む\n\n/ai\n\n[\n  \"あとで読む\"\n]\n\n/human\n\n読んだ\n\n/ai\n\n[\n  \"読んだ\"\n]\n\n/human\n\n期待\n\n/ai\n\n[\n  \"期待\"\n]","model":"gpt-4o-mini"},"clustering":{"clusters":8,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # 必要なモジュールのインポート\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdの辞書パスを指定\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # 品詞フィルタリングを行うトークナイザー\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # 名詞、動詞、形容詞だけを抽出する\n            if node.feature.startswith('名詞') or node.feature.startswith('動詞') or node.feature.startswith('形容詞'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # 日本語のストップワードリストを作成（必要に応じて拡張可能）\n    japanese_stopwords = [\"これ\", \"それ\", \"あれ\", \"こと\", \"もの\", \"ため\", \"よう\", \"さん\", \"する\", \"なる\", \"ある\", \"いる\"]\n\n    # 日本語トークナイザーとストップワードを使用する\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # トピックモデルのフィッティング\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"},"intro":"このレポートは、Slidoに集まったコメントを元にAIによって生成されました。","output_dir":"CreativeMTG","previous":{"name":"Creative MTG 反応まとめ","question":"Creative MTGの参加者の反応にはどういう傾向があったのか","input":"CreativeMTG","model":"gpt-4o-mini","extraction":{"workers":3,"limit":273,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nあなたはプロのリサーチアシスタントであり、私の仕事は論拠のきれいなデータセットを準備することです。\n\n背景として、私はCreative MTGに参加した人のコメントを集めています。\nCreative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nCreative MTGでどのような反応があったのかを分類するお手伝いをしていただきたいです。\nこれから与えるのはCreative MTGに参加した人のコメントのリストです。\nこれから与える投稿をJSONリストとして返してほしい。\n本当に必要な場合は、2つ以上の別々の意見に分けることもできるが、1つのトピックを返すのが最善であることが多いだろう。\n以下にポストを要約する際の事例を挙げます。\nこれらはあくまで文脈の切り離された例であり、この例で与えた文章を返すことはしないでください。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\n\n\n/human\n\n気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\n\n/ai \n\n[\n  \"気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\"\n]\n\n/human \n\n豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\n\n/ai \n\n[\n  \"豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\",\n]\n\n/human\n\nAI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\n\n/ai\n\n[\n  \"AI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\"\n]\n\n\n/human\n\nいい\n\n/ai\n\n[\n  \"いい\"\n]\n\n/human\n\nあとで読む\n\n/ai\n\n[\n  \"あとで読む\"\n]\n\n/human\n\n読んだ\n\n/ai\n\n[\n  \"読んだ\"\n]\n\n/human\n\n期待\n\n/ai\n\n[\n  \"期待\"\n]","model":"gpt-4o-mini"},"clustering":{"clusters":8,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # 必要なモジュールのインポート\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdの辞書パスを指定\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # 品詞フィルタリングを行うトークナイザー\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # 名詞、動詞、形容詞だけを抽出する\n            if node.feature.startswith('名詞') or node.feature.startswith('動詞') or node.feature.startswith('形容詞'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # 日本語のストップワードリストを作成（必要に応じて拡張可能）\n    japanese_stopwords = [\"これ\", \"それ\", \"あれ\", \"こと\", \"もの\", \"ため\", \"よう\", \"さん\", \"する\", \"なる\", \"ある\", \"いる\"]\n\n    # 日本語トークナイザーとストップワードを使用する\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # トピックモデルのフィッティング\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"},"intro":"このレポートは、Slidoに集まったコメントを元にAIによって生成されました。","output_dir":"CreativeMTG","embedding":{"source_code":"\nfrom langchain_community.embeddings import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、Creative MTGに関する一連のコメントに対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。\nCreative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\n質問からすでに明らかな文脈は含めない（「Creative MTGの参加者の反応にはどういう傾向があったのか」のようなものであれば、クラスターのラベルに「Creative MTGの参加者の反応」と繰り返す必要はない）。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\nラベルは全て重複してはならない。\n「参加者の反応の傾向」「参加者の具体的な反応」のようなものはやめてください。\nクラスター外の論点と明確に区別されるようなラベルを回答してください。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o-mini"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nあなたはシンクタンクで働くリサーチアシスタントのエキスパートです。Creative MTGに参加した人のコメントのリストが渡されます。\nCreative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたは、主な要点を1~2段落にまとめて回答します。あなたは簡潔で読みやすい短い文章を書くことができます。 \n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o-mini"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、その結果を簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\n補足として、Creative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。","model":"gpt-4o-mini"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":false,"reason":"nothing changed"},{"step":"embedding","run":false,"reason":"nothing changed"},{"step":"clustering","run":false,"reason":"nothing changed"},{"step":"labelling","run":true,"reason":"some parameters changed: prompt"},{"step":"takeaways","run":false,"reason":"nothing changed"},{"step":"overview","run":true,"reason":"some dependent steps will re-run: labelling"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: labelling, overview"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"completed","start_time":"2024-11-26T17:07:04.595562","completed_jobs":[{"step":"labelling","completed":"2024-11-26T17:07:12.870921","duration":8.268707,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、Creative MTGに関する一連のコメントに対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。\nCreative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\n質問からすでに明らかな文脈は含めない（「Creative MTGの参加者の反応にはどういう傾向があったのか」のようなものであれば、クラスターのラベルに「Creative MTGの参加者の反応」と繰り返す必要はない）。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\nラベルは全て重複してはならない。\n「参加者の反応の傾向」「参加者の具体的な反応」のようなものはやめてください。\nクラスター外の論点と明確に区別されるようなラベルを回答してください。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o-mini"}},{"step":"overview","completed":"2024-11-26T17:07:14.192292","duration":1.318819,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、その結果を簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\n補足として、Creative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。","model":"gpt-4o-mini"}},{"step":"aggregation","completed":"2024-11-26T17:07:14.319903","duration":0.12464,"params":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"}},{"step":"visualization","completed":"2024-11-26T17:07:32.797704","duration":18.476668,"params":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"}}],"lock_until":"2024-11-26T17:12:32.799801","current_job":"visualization","current_job_started":"2024-11-26T17:07:14.321127","current_job_progress":null,"current_jop_tasks":null,"previously_completed_jobs":[{"step":"extraction","completed":"2024-11-26T16:49:07.725392","duration":122.077406,"params":{"workers":3,"limit":273,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nあなたはプロのリサーチアシスタントであり、私の仕事は論拠のきれいなデータセットを準備することです。\n\n背景として、私はCreative MTGに参加した人のコメントを集めています。\nCreative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nCreative MTGでどのような反応があったのかを分類するお手伝いをしていただきたいです。\nこれから与えるのはCreative MTGに参加した人のコメントのリストです。\nこれから与える投稿をJSONリストとして返してほしい。\n本当に必要な場合は、2つ以上の別々の意見に分けることもできるが、1つのトピックを返すのが最善であることが多いだろう。\n以下にポストを要約する際の事例を挙げます。\nこれらはあくまで文脈の切り離された例であり、この例で与えた文章を返すことはしないでください。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\n\n\n/human\n\n気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\n\n/ai \n\n[\n  \"気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\"\n]\n\n/human \n\n豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\n\n/ai \n\n[\n  \"豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\",\n]\n\n/human\n\nAI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\n\n/ai\n\n[\n  \"AI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\"\n]\n\n\n/human\n\nいい\n\n/ai\n\n[\n  \"いい\"\n]\n\n/human\n\nあとで読む\n\n/ai\n\n[\n  \"あとで読む\"\n]\n\n/human\n\n読んだ\n\n/ai\n\n[\n  \"読んだ\"\n]\n\n/human\n\n期待\n\n/ai\n\n[\n  \"期待\"\n]","model":"gpt-4o-mini"}},{"step":"embedding","completed":"2024-11-26T16:49:11.516241","duration":3.789071,"params":{"source_code":"\nfrom langchain_community.embeddings import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"}},{"step":"clustering","completed":"2024-11-26T16:49:42.503261","duration":30.985021,"params":{"clusters":8,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # 必要なモジュールのインポート\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdの辞書パスを指定\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # 品詞フィルタリングを行うトークナイザー\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # 名詞、動詞、形容詞だけを抽出する\n            if node.feature.startswith('名詞') or node.feature.startswith('動詞') or node.feature.startswith('形容詞'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # 日本語のストップワードリストを作成（必要に応じて拡張可能）\n    japanese_stopwords = [\"これ\", \"それ\", \"あれ\", \"こと\", \"もの\", \"ため\", \"よう\", \"さん\", \"する\", \"なる\", \"ある\", \"いる\"]\n\n    # 日本語トークナイザーとストップワードを使用する\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # トピックモデルのフィッティング\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"}},{"step":"takeaways","completed":"2024-11-26T16:50:11.130326","duration":22.866453,"params":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nあなたはシンクタンクで働くリサーチアシスタントのエキスパートです。Creative MTGに参加した人のコメントのリストが渡されます。\nCreative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたは、主な要点を1~2段落にまとめて回答します。あなたは簡潔で読みやすい短い文章を書くことができます。 \n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o-mini"}}],"end_time":"2024-11-26T17:07:32.799784"},"embedding":{"source_code":"\nfrom langchain_community.embeddings import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、Creative MTGに関する一連のコメントに対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。\nCreative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\n質問からすでに明らかな文脈は含めない（「Creative MTGの参加者の反応にはどういう傾向があったのか」のようなものであれば、クラスターのラベルに「Creative MTGの参加者の反応」と繰り返す必要はない）。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\nラベルは全て重複してはならない。\n「参加者の反応の傾向」「参加者の具体的な反応」のようなものはやめてください。\n参加者の反応が具体的にどのような傾向にあったのかが知りたいです。\nクラスター外の論点と明確に区別されるようなラベルを回答してください。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o-mini"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nあなたはシンクタンクで働くリサーチアシスタントのエキスパートです。Creative MTGに参加した人のコメントのリストが渡されます。\nCreative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたは、主な要点を1~2段落にまとめて回答します。あなたは簡潔で読みやすい短い文章を書くことができます。 \n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o-mini"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、その結果を簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\n補足として、Creative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。","model":"gpt-4o-mini"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":false,"reason":"nothing changed"},{"step":"embedding","run":false,"reason":"nothing changed"},{"step":"clustering","run":false,"reason":"nothing changed"},{"step":"labelling","run":true,"reason":"some parameters changed: prompt"},{"step":"takeaways","run":false,"reason":"nothing changed"},{"step":"overview","run":true,"reason":"some dependent steps will re-run: labelling"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: labelling, overview"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"running","start_time":"2024-11-26T17:12:46.938153","completed_jobs":[{"step":"labelling","completed":"2024-11-26T17:12:54.102309","duration":7.159544,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、Creative MTGに関する一連のコメントに対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。\nCreative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\n質問からすでに明らかな文脈は含めない（「Creative MTGの参加者の反応にはどういう傾向があったのか」のようなものであれば、クラスターのラベルに「Creative MTGの参加者の反応」と繰り返す必要はない）。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\nラベルは全て重複してはならない。\n「参加者の反応の傾向」「参加者の具体的な反応」のようなものはやめてください。\n参加者の反応が具体的にどのような傾向にあったのかが知りたいです。\nクラスター外の論点と明確に区別されるようなラベルを回答してください。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o-mini"}},{"step":"overview","completed":"2024-11-26T17:12:55.810438","duration":1.704887,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、その結果を簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\n補足として、Creative MTGでは、「ComoNe」「AKXY」「怪談と窒素」という3つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。","model":"gpt-4o-mini"}}],"lock_until":"2024-11-26T17:17:55.815711","current_job":"aggregation","current_job_started":"2024-11-26T17:12:55.815682","current_job_progress":null,"current_jop_tasks":null}}},"__N_SSG":true},"page":"/","query":{},"buildId":"PPoKqxoD2OrYMyxE9sc3b","assetPrefix":".","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>